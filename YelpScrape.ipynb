{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, bs4, time, csv, math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_url = open('michelin_urls.csv')\n",
    "m_url = csv.reader(m_url)\n",
    "m_url = list(m_url)\n",
    "m_url = m_url[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_restaurant_data(d):\n",
    "\n",
    "    r_dict = {}\n",
    "    restaurant_name = 'Unknown' if d.select('h1.biz-page-title.embossed-text-white')[0].string is None else\\\n",
    "    d.select('h1.biz-page-title.embossed-text-white')[0].string.encode('ascii','ignore').strip()\n",
    "    \n",
    "    overall_rating = 'Unknown' if d.find_all('meta', {'itemprop': 'ratingValue'})[0].get('content') is None else\\\n",
    "    d.find_all('meta', {'itemprop': 'ratingValue'})[0].get('content')\n",
    "    \n",
    "    total_reviews = 'Unknown' if d.find_all('span', {'itemprop': 'reviewCount'})[0].string is None else\\\n",
    "    d.find_all('span', {'itemprop': 'reviewCount'})[0].string\n",
    "    \n",
    "    price_range = 'Unknown' if d.find_all('span', {'class': 'business-attribute price-range'})[0].string is None else\\\n",
    "    d.find_all('span', {'class': 'business-attribute price-range'})[0].string.encode('ascii','ignore')\n",
    "    \n",
    "    range_name = 'Unknown' if d.find_all('dd', {'class': 'nowrap price-description'})[0].string is None else\\\n",
    "    d.find_all('dd', {'class': 'nowrap price-description'})[0].string.encode('ascii','ignore').strip()\n",
    "    \n",
    "    address_street = 'Unknown' if d.find_all('span', {'itemprop': 'streetAddress'})[0].string is None else\\\n",
    "    d.find_all('span', {'itemprop': 'streetAddress'})[0].string.encode('ascii','ignore')\n",
    "    \n",
    "    address_city = 'Unknown' if d.find_all('span', {'itemprop': 'addressLocality'})[0].string is None else\\\n",
    "    d.find_all('span', {'itemprop': 'addressLocality'})[0].string.encode('ascii','ignore')\n",
    "    \n",
    "    address_state = 'Unknown' if d.find_all('span', {'itemprop': 'addressRegion'})[0].string is None else\\\n",
    "    d.find_all('span', {'itemprop': 'addressRegion'})[0].string.encode('ascii','ignore')\n",
    "    \n",
    "    address_zip = 'Unknown' if d.find_all('span', {'itemprop': 'postalCode'})[0].string is None else\\\n",
    "    d.find_all('span', {'itemprop': 'postalCode'})[0].string.encode('ascii','ignore')\n",
    "\n",
    "    r_dict['restaurant_name'] = restaurant_name\n",
    "    r_dict['review_rating'] = overall_rating\n",
    "    r_dict['total_reviews'] = total_reviews\n",
    "    r_dict['price_range'] = price_range\n",
    "    r_dict['range_name'] = range_name\n",
    "    r_dict['address_street'] = address_street\n",
    "    r_dict['address_city'] = address_city\n",
    "    r_dict['address_state'] = address_state\n",
    "    r_dict['address_zip'] = address_zip\n",
    "\n",
    "    \n",
    "    return r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_review_data(d):\n",
    "    r_list = []\n",
    "    rev_data1 = d.find_all(\"ul\", { \"class\" : \"user-passport-stats\" })\n",
    "    rev_data2 = d.find_all('li', {'class': 'user-location responsive-hidden-small'})\n",
    "    rev_data3 = d.find_all('meta', {'itemprop': 'ratingValue'})[1:] #excludes first item which is overall rating\n",
    "    rev_data4 = d.find_all('meta', {'itemprop': 'datePublished'})\n",
    "    rev_data5 = d.find_all('p', {'itemprop': 'description'})\n",
    "    \n",
    "    for i in enumerate(rev_data1):\n",
    "        r_dict = dict()\n",
    "        r_dict['friend_count'] = '0' if (i[1].find_all('li', {'class': 'friend-count responsive-small-display-inline-block'})[0].find_all('b')[0].string) is None\\\n",
    "        else (i[1].find_all('li', {'class': 'friend-count responsive-small-display-inline-block'})[0].find_all('b')[0].string.encode('ascii','ignore'))  \n",
    "\n",
    "        r_dict['review_count'] = '0' if (i[1].find_all('li', {'class': 'review-count responsive-small-display-inline-block'})[0].find_all('b')[0].string) is None\\\n",
    "        else (i[1].find_all('li', {'class': 'review-count responsive-small-display-inline-block'})[0].find_all('b')[0].string.encode('ascii','ignore'))\n",
    "\n",
    "        r_dict['is_elite'] = 'No' if i[1].find_all('li', {'class': 'is-elite responsive-small-display-inline-block'}) == [] else 'Yes'\n",
    "\n",
    "        rev_data2i = \"Unknown\" if rev_data2[i[0]].find_all('b')[0].string is None else rev_data2[i[0]].find_all('b')[0].string.encode('ascii', 'ignore')\n",
    "        r_dict['reviewer_location'] = rev_data2i\n",
    "\n",
    "        rev_data3i = 'Unknown' if rev_data3[i[0]].get('content') is None else rev_data3[i[0]].get('content')\n",
    "        r_dict['review_rating'] = rev_data3i\n",
    "\n",
    "        rev_data4i = 'Unknown' if rev_data4[i[0]].get('content') is None else rev_data4[i[0]].get('content')\n",
    "        r_dict['review_date'] = rev_data4i\n",
    "\n",
    "        rev_data5i = 'None' if rev_data5[i[0]].getText() is None else rev_data5[i[0]].getText().encode('ascii','ignore')\n",
    "        r_dict['review_content'] = rev_data5i\n",
    "\n",
    "        res_data5i = d.select('h1.biz-page-title.embossed-text-white')[0].string.encode('ascii','ignore').strip()\n",
    "        r_dict['restaurant_name'] = res_data5i\n",
    "\n",
    "        r_list.append(r_dict)\n",
    "    \n",
    "    return r_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_cycle(u_file, p = 0):\n",
    "    rest_list = []\n",
    "    rev_list = []\n",
    "    for i in u_file:\n",
    "        try:\n",
    "            f = bs4.BeautifulSoup(requests.get(i[0]).text)\n",
    "            r = get_restaurant_data(f)\n",
    "            total_review_count = int(r['total_reviews'])\n",
    "            pages = range(0,total_review_count,20) # this is missing first page, url of 0 doesn't work\n",
    "            print i\n",
    "#             rest_list.append(r)\n",
    "#             time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print i\n",
    "            print e\n",
    "            print '_'*60\n",
    "            pass\n",
    "            \n",
    "        for j in pages[p:len(pages)+1]:\n",
    "            try:\n",
    "                d = bs4.BeautifulSoup(requests.get(str(i[0])+'?sort_by=date_desc&start='+str(j)).text)\n",
    "                rv = get_review_data(d)\n",
    "#                 print rv\n",
    "                print j\n",
    "                rev_list.append(rv)\n",
    "                time.sleep(4)\n",
    "            except Exception as e2:\n",
    "                print 'i = ' + str(i)\n",
    "                print 'j = ' + str(j)\n",
    "                print e2\n",
    "                print '_'*60\n",
    "                pass\n",
    "            \n",
    "    return rev_list #rest_list, rev_list               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "michelin_rest_scrape = []\n",
    "michelin_rev_scrape = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.yelp.com/biz/solbar-calistoga']\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "['http://www.yelp.com/biz/luce-san-francisco']\n"
     ]
    }
   ],
   "source": [
    "michelin_rest_scrape.append(url_cycle(m_url[0:]))\n",
    "michelin_rev_scrape.append(url_cycle(m_url[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(michelin_rest_scrape[0]).to_csv('non_michelin_restaurant_data.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flattened_list = []\n",
    "for x in michelin_rev_scrape:\n",
    "    for y in x:\n",
    "        flattened_list.append(y)\n",
    "new_flattened_list = []\n",
    "for x in flattened_list:\n",
    "    for y in x:\n",
    "        new_flattened_list.append(y)\n",
    "# print new_flattened_list\n",
    "pd.DataFrame(new_flattened_list).to_csv('michelin_review_data.csv', header = True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
